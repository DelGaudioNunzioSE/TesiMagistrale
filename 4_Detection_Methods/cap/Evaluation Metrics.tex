\section{Evaluation Metrics}
Let us recall that the ultimate goal is to build a 
binary classifier capable of determining whether a piece 
of source code was written by a human or generated by a 
Large Language Model (LLM). For binary classifiers, 
\textbf{accuracy} is typically the default evaluation 
metric, unless one classification outcome, such as true 
positives or false positives, is considered more critical 
than the other. 

Given that this classifier can be used 
in scenarios where a programmer could be 'accused' of 
not having authored the code themselves, it is essential 
that such claims be made with a high degree of confidence. 
While it is certainly desirable to allow end users to 
configure the decision threshold, the default setting 
should prioritize a \textbf{low FPR} (false positive rate) 
to prevent unjust accusations.
\begin{quote}
    “In previous experiments, we mainly use F1 score, 
    which is a threshold-dependent measure that balances 
    precision and recall, but F1 can be misleading in 
    real-world detection tasks. As it gives equal weight 
    to false positives and false negatives […] it often 
    fails to reflect performance in imbalanced settings or 
    under strict false-alarm constraints. By contrast, 
    reporting the true positive rate at low false-positive 
    rates directly measures how many genuine positives the 
    model catches when false alarms must be kept to a minimum.”
    \cite{guo2025codemirage}.
\end{quote}