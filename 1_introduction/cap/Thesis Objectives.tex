\clearpage

\section{Thesis Objectives}
This thesis aims to pursue a structured series 
of objectives, each forming a necessary foundation 
for the subsequent stage of the project.

The overarching goal is to \textbf{develop a software 
tool capable of reliably distinguishing source 
code written by humans from that generated by 
Large Language Models} (LLMs). Given the lack of 
standardization in the current literature, this 
project first seeks to \textbf{establish a fair and 
reproducible evaluation framework}.

The initial task involves \textbf{selecting} a 
sympathetic and representative \textbf{dataset} 
that can serve both for retraining detection 
models and for evaluating their performance 
consistently. A comparative analysis of 
current scientific literature datasets 
will be conducted, taking into 
account objective criteria such as class 
balance, diversity of programming languages, 
code length variability, and feature distribution. 
The selected dataset will play a central role in 
ensuring that all subsequent experiments are 
comparable and grounded on a common basis.

Once the dataset is established, the next 
phase consists in \textbf{collecting and systematically 
evaluating the various detection models 
suggested in recent literature}. These models 
will be executed on the selected dataset 
using consistent and comparable metrics in 
order to allow for a meaningful comparison. 
Special attention will be given to 
understanding the limitations 
of each model like the specific scenarios in 
which they demonstrate optimal or suboptimal performance.

Following this benchmarking effort, the 
most promising method will be selected for 
further investigation. At this stage, will be
proposed enhancements aimed at improving accuracy, 
robustness, or efficiency. These improvements 
must be tailored to the nature of the selected 
model.

The final phase of the project will focus on 
the development of a usable and \textbf{user-friendly 
software interface}, which allows end users 
to apply the selected detection model with 
minimal technical effort. The interface may 
include customizable parameters such as 
confidence thresholds or model options, 
depending on the characteristics of the 
adopted approach. Particular care will be 
taken to ensure that the tool is accessible 
and adaptable, so that it can be employed in 
diverse real-world scenarios, from academic 
integrity enforcement to software development auditing.
Ultimately, this thesis intends to contribute 
both a rigorous comparative study and a 
practical, operational tool, filling a 
current gap in the literature and paving 
the way for future research and application 
in this emerging area
