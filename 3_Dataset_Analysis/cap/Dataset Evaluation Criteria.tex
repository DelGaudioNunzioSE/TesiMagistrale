\clearpage
\section{Dataset Evaluation Criteria}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%Considerare i PROMPT usati per la generazione di codiCe AI
% Considerare quali modelli AI sono stati usati per la generazione di codice: 
%% 1 quanto sono diversi i modelli tra loro (chat3.5 e chat 4 sono considerabili simili) 
%% 2 quanto moderni
% valutazioni della corettezza del codice
% diversità nel codice umano:
%% 1 numero di diversi macro-problemi
%% 2 diversa grandezza 
%% 3 test che dimostrano che funziona
% Considerare qualità del codice ai
%% 1 grandezza codice
%% 2 test che dimostrino che funziona
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5



All datasets made publicly available by the scientific 
community will be carefully analysed and compared. 
The goal is to identify the most suitable dataset—either 
directly or through integration—for the evaluation of code 
detection methods under consistent conditions. Each dataset 
will be assessed based on the following criteria:

\begin{itemize}
    \item \textbf{Total number of code samples available:} 
    A larger number of samples generally improves statistical 
    robustness during evaluation and model training.
    
    \item \textbf{Number of LLMs used to generate synthetic code:} 
    Datasets that include code generated by multiple LLMs are better 
    suited for evaluating a method’s generalization capability.
    
    \item \textbf{Diversity among LLMs used:} It is important to 
    consider not only the number but also the variety of LLMs (e.g., 
    transformer architecture, training corpus, or fine-tuning strategies).
    
    \item \textbf{Level of control and metadata availability:} 
    This includes whether the dataset provides information on the 
    validity of human-written code, the exact prompts used to generate 
    LLM code, or whether code quality and correctness have been validated.
    
    \item \textbf{Programming languages covered and their distribution:} 
    The range of programming languages and the number of code samples per 
    language will be analyzed to assess linguistic diversity and prevent 
    language-specific overfitting.
    
    \item \textbf{Composition by code type (functional vs. object-oriented):} 
    The balance between functional and object-oriented code will be considered, 
    as different styles may influence detection performance and feature extraction strategies.
\end{itemize}
