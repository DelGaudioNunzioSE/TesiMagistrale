\subsection{AIGCodeSet}
\label{section:AiGCodeSet}
The main contribution of this paper is also the preparation 
of a dataset for evaluating detection methods. Unlike other 
works, this dataset includes both functional and non-functional 
human-written code, as it evaluates LLM code generation starting 
both from a plain prompt and from existing code.


\begin{itemize}
    \item \textbf{Gemini 1.5 Flash} \cite{team2024gemini} : 
    Proprietary, available via Google Cloud’s Gemini API and Vertex AI; 
    no public weights. Multimodal corpora including code, text, images, 
    audio, and video; extends context handling to millions of tokens. 
    \item \textbf{Codestral-22B} \cite{mistral-codestral-2024} : 
    Autoregressive code modeling with fill‑in‑the‑middle (FIM) 
    capability; excels at cross‑file completion tasks.
    \item \textbf{CodeLlama-34B} \cite{roziere2023code} :
    State‑of‑the‑art among open models on HumanEval.
\end{itemize}




%%%%
%%%%

\subsubsection*{Strengths}
\begin{itemize}
    \item They evaluate LLM code generation under three different scenarios 
    {(\scriptsize\textit{Section 3.2:Generating Code Snippets})}:
    \begin{itemize}
        \item textual problem descriptions taken from CodeNet (problem prompt);
        \item problem prompt + human source code with a runtime error;
        \item problem prompt + human source code with an output error.
    \end{itemize}
    \item The official dataset on 
    \href{{https://huggingface.co/datasets/basakdemirok/AIGCodeSet}}{huggingface}
    is well documented. 
    \item The problems are of varying difficulty.
\end{itemize}


%%%%
%%%%
\subsubsection*{Weaknesses}
\begin{itemize}
    \item The dataset contains python code only.
    \item The dataset contain competitive code only.
    \item All the codes are solution of \textbf{only 300 problems} 
    \textit{(60 problem x 5 different difficulty)}
    \item GPT, probably the most widely LLM family 
    used among students, is not 
    included among the evaluated models.
\end{itemize}


%%%%
%%%%
\subsubsection*{Code Quality}
In order to preserve quality in the LLMs code source:
\begin{itemize}
    \item \textit{"failure to produce any output"}
    \item \textit{"inclusion of code written in C-family languages instead of Python."}
    \item \textit{"presence of meaningless characters, sentences, numbers, or dots."}
    \item \textit{"we manually removed any explanations provided above or below the code.
    "However, \textbf{comments embedded within the code blocks were retained}, provided they were 
    appropriately marked as comment lines.""}
\end{itemize}


%%%%
%%%%
\subsubsection*{Final evaluation}


\expandafter\def\csname AIGCodeSetHumanCode\endcsname{4,755}
\expandafter\def\csname AIGCodeSetLLMCode\endcsname{2,828}
\expandafter\def\csname AIGCodeSetNumLLMs\endcsname{3 \textit{Gemini 1.5 Flash, Codestral-22B, CodeLlama-34B}}
\expandafter\def\csname AIGCodeSetLLMDiversity\endcsname{3 different source models}
\expandafter\def\csname AIGCodeSetCurrentUse\endcsname{Average LLMs release date: 2024 \textit{now exist Gemini-2.0}}
\expandafter\def\csname AIGCodeSetLanguages\endcsname{Python}
\expandafter\def\csname AIGCodeSetCodeTypes\endcsname{unspecified}
\expandafter\def\csname AIGCodeSetCodeSize\endcsname{1\textsuperscript{st} percentile: 30 words,\newline 3\textsuperscript{rd} percentile: 50 words}
\expandafter\def\csname AIGCodeSetCodeContext\endcsname{competitive}
\expandafter\def\csname AIGCodeSetPrompts\endcsname{provided}
\expandafter\def\csname AIGCodeSetSources\endcsname{CodeNet by IBM \cite{puri2021codenet}}
\expandafter\def\csname AIGCodeSetCodeQuality\endcsname{Executable check}
\expandafter\def\csname AIGCodeSetReliability\endcsname{Hight}


\evaluationTable{AIGCodeSet}


The dataset appears to be of high quality, but compared to other works, 
the variety of code is extremely limited.
Moreover, GPT is not included among the LLMs, and there is no guarantee that 
the LLM-generated code actually functions correctly.