@article{base,
  author    = {Ye, Tianyu and Du, Yujia and Ma, Tong and Wu, Lijun and Zhang, Xinyu and Ji, Shuang and Wang, Wei},
  title     = {Uncovering LLM-Generated Code: A Zero-Shot Synthetic Code Detector via Code Rewriting},
  year      = {2025},
  journal   = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume    = {39},
  number    = {1},
  pages     = {968--976},
  doi       = {10.1609/aaai.v39i1.3208}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% INTRODUCTION

@article{chowdhery2022palm,
  title={PaLM: Scaling Language Modeling with Pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and et al.},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{touvron2023llama,
  title={LLaMA: Open and Efficient Foundation Language Models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and et al.},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@misc{anthropic2023claude,
  title={Claude: The Anthropic Language Model},
  author={Anthropic},
  year={2023},
  howpublished={\url{https://www.anthropic.com/index/introducing-claude}}
}

@article{jiang2023mistral,
  title={Introducing Mistral: A High-Performance Language Model},
  author={Jiang, Jianfeng and et al.},
  journal={Mistral AI},
  year={2023},
  howpublished={\url{https://mistral.ai/news/introducing-mistral-7b/}}
}


@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and et al.},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{brown2020language,
  title={Language Models are Few-Shot Learners},
  author={Brown, Tom and et al.},
  journal={NeurIPS},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@misc{openai2023gpt4,
  title={GPT-4 Technical Report},
  author={OpenAI},
  year={2023},
  howpublished={\url{https://openai.com/research/gpt-4}}
}

@inproceedings{chen2021codex,
  title={Evaluating Large Language Models Trained on Code},
  author={Chen, Mark and et al.},
  booktitle={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{roziere2023code,
  title={Code LLaMA: Open Foundation Models for Code},
  author={Roziere, Baptiste and et al.},
  journal={arXiv preprint arXiv:2308.12950},
  year={2023}
}

@article{rombach2022high,
  title={High-Resolution Image Synthesis with Latent Diffusion Models},
  author={Rombach, Robin and et al.},
  journal={CVPR},
  year={2022}
}

@misc{google2024veo,
  author    = {Google DeepMind},
  title     = {Veo: Advancing Generative Video Models},
  year      = {2024},
  howpublished = {\url{https://deepmind.google/technologies/veo}}
}

@article{warwick2016turing,
  title={Can Machines Think? A Report on Turing Test Experiments at the Royal Society},
  author={Warwick, Kevin and Shah, Huma},
  journal={Journal of Experimental \& Theoretical Artificial Intelligence},
  volume={28},
  number={6},
  pages={989--1007},
  year={2016}
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%1.1
@article{weizenbaum1966eliza,
  title={ELIZA—a computer program for the study of natural language communication between man and machine},
  author={Weizenbaum, Joseph},
  journal={Communications of the ACM},
  volume={9},
  number={1},
  pages={36--45},
  year={1966}
}

@article{mikolov2013efficient,
  title={Efficient Estimation of Word Representations in Vector Space},
  author={Mikolov, Tomas and et al.},
  journal={arXiv preprint arXiv:1301.3781},
  year={2013}
}

@inproceedings{pennington2014glove,
  title={GloVe: Global Vectors for Word Representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D.},
  booktitle={EMNLP},
  year={2014}
}

@article{radford2019language,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and et al.},
  journal={OpenAI Blog},
  volume={1},
  number={8},
  year={2019}
}

@inproceedings{chen2021codex,
  title={Evaluating Large Language Models Trained on Code},
  author={Chen, Mark and et al.},
  booktitle={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{wang2021codet5,
  title={CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation},
  author={Wang, Yue and et al.},
  journal={arXiv preprint arXiv:2109.00859},
  year={2021}
}

@article{nijkamp2022codegen,
  title={CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis},
  author={Nijkamp, Erik and et al.},
  journal={arXiv preprint arXiv:2203.13474},
  year={2022}
}

@article{zeng2022codegeex,
  title={CodeGeeX: A Pre-trained Model for Code Generation with Cross-Programming-Language Evaluation},
  author={Zeng, Guolin and et al.},
  journal={arXiv preprint arXiv:2203.13474},
  year={2022}
}

@article{roziere2023code,
  title={Code LLaMA: Open Foundation Models for Code},
  author={Roziere, Baptiste and et al.},
  journal={arXiv preprint arXiv:2308.12950},
  year={2023}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 1.1.2
@article{backus1957fortran,
  title={The FORTRAN automatic coding system},
  author={Backus, John and et al.},
  journal={Proceedings of the Western Joint Computer Conference},
  year={1957},
  pages={188--198}
}

@misc{stallman1981emacs,
  title={EMACS: The extensible, customizable self-documenting display editor},
  author={Stallman, Richard M.},
  year={1981},
  howpublished={\url{https://www.gnu.org/software/emacs/}}
}

@misc{xslt1999,
  author={W3C},
  title={XSL Transformations (XSLT) Version 1.0},
  year={1999},
  howpublished={\url{https://www.w3.org/TR/xslt}}
}

@inproceedings{zelle1996learning,
  title={Learning to parse database queries using inductive logic programming},
  author={Zelle, John M. and Mooney, Raymond J.},
  booktitle={AAAI/IAAI, Vol. 2},
  year={1996},
  pages={1050--1055}
}

@inproceedings{mooney1997nlidb,
  title={Learning semantic parsers: An important but under-studied application of machine learning},
  author={Mooney, Raymond J.},
  booktitle={Proceedings of the AAAI Spring Symposium on Natural Language Processing for the World Wide Web},
  year={1997}
}

@misc{jinja2docs,
  title={Jinja2 Documentation},
  author={Pallets Projects},
  year={2005},
  howpublished={\url{https://jinja.palletsprojects.com/}}
}

@misc{makoengine,
  title={Mako Templates for Python},
  author={Mike Bayer},
  year={2006},
  howpublished={\url{https://www.makotemplates.org/}}
}

@inproceedings{yin2017syntactic,
  title={A syntactic neural model for general-purpose code generation},
  author={Yin, Pengcheng and Neubig, Graham},
  booktitle={ACL},
  year={2017}
}

@inproceedings{chen2021codex,
  title={Evaluating Large Language Models Trained on Code},
  author={Chen, Mark and et al.},
  booktitle={arXiv preprint arXiv:2107.03374},
  year={2021}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%1.1.3
@article{devlin2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={NAACL},
  year={2019}
}

@article{radford2018improving,
  title={Improving Language Understanding by Generative Pre-Training},
  author={Radford, Alec and et al.},
  journal={OpenAI blog},
  year={2018}
}

@misc{tabnine2019,
  author={TabNine},
  title={TabNine: Autocomplete AI},
  year={2019},
  howpublished={\url{https://www.tabnine.com/}}
}

@article{husain2019codesearchnet,
  title={CodeSearchNet Challenge: Evaluating the State of Semantic Code Search},
  author={Husain, Hamel and et al.},
  journal={arXiv preprint arXiv:1909.09436},
  year={2019}
}

@article{feng2020codebert,
  title={CodeBERT: A Pre-Trained Model for Programming and Natural Languages},
  author={Feng, Zhangyin and et al.},
  journal={EMNLP},
  year={2020}
}

@article{austin2021mbpp,
  title={Program Synthesis with Large Language Models},
  author={Austin, Jacob and et al.},
  journal={arXiv preprint arXiv:2108.07732},
  year={2021}
}

@article{hendrycks2021apps,
  title={Measuring Coding Challenge Competence With APPS},
  author={Hendrycks, Dan and et al.},
  journal={arXiv preprint arXiv:2105.09938},
  year={2021}
}

@article{lu2021codexglue,
  title={CodeXGLUE: A Benchmark Dataset and Open Challenge for Code Intelligence},
  author={Lu, Shuo and et al.},
  journal={arXiv preprint arXiv:2102.04664},
  year={2021}
}

@article{li2022alphacode,
  title={Competition-level Code Generation with AlphaCode},
  author={Li, Yujia and et al.},
  journal={arXiv preprint arXiv:2203.07814},
  year={2022}
}

@article{xu2022polycoder,
  title={PolyCoder: An Open-Source Programming Language Model},
  author={Xu, Alexander and et al.},
  journal={arXiv preprint arXiv:2202.13169},
  year={2022}
}

@article{google2024gemini,
  title={Gemini: Unlocking Multimodal Understanding and Reasoning},
  author={Google DeepMind},
  year={2024},
  howpublished={\url{https://deepmind.google/technologies/gemini/}}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{orel2025codetm4,
  author = {Orel, D. and Azizov, D. and Nakov, P.},
  title = {CoDet-M4: Detecting Machine-Generated Code in Multi-Lingual, Multi-Generator and Multi-Domain Settings},
  journal = {arXiv preprint arXiv:2503.13733},
  year = {2025},
  url = {https://arxiv.org/abs/2503.13733},
}

@article{demirok2025aigcodeset,
  author = {Demirok, B. and Kutlu, M.},
  title = {AIGCodeSet: A New Annotated Dataset for AI Generated Code Detection},
  journal = {arXiv preprint arXiv:2412.16594},
  year = {2025},
  url = {https://arxiv.org/abs/2412.16594},
}

@article{suh2024empirical,
  author = {Suh, H. and Tafreshipour, M. and Li, J. and Bhattiprolu, A. and Ahmed, I.},
  title = {An Empirical Study on Automatically Detecting AI-Generated Source Code: How Far Are We?},
  journal = {arXiv preprint arXiv:2411.04299},
  year = {2024},
  url = {https://arxiv.org/abs/2411.04299},
}

@article{nguyen2023snippet,
  author = {Nguyen, P. T. and Di Rocco, J. and Di Sipio, C. and Rubei, R. and Di Ruscio, D. and Di Penta, M.},
  title = {Is this snippet written by ChatGPT? An empirical study with a CodeBERT-based classifier},
  journal = {arXiv preprint arXiv:2307.09381},
  year = {2023},
  url = {https://arxiv.org/abs/2307.09381},
}

@article{xu2025codevision,
  author = {Xu, Z. and Sheng, V. S.},
  title = {CodeVision: Detecting LLM-Generated Code Using 2D Token Probability Maps and Vision Models},
  journal = {arXiv preprint arXiv:2501.03288},
  year = {2025},
  url = {https://arxiv.org/abs/2501.03288},
}

@article{ye2025uncovering,
  author = {Ye, T. and Du, Y. and Ma, T. and Wu, L. and Zhang, X. and Ji, S. and Wang, W.},
  title = {Uncovering LLM-Generated Code: A Zero-Shot Synthetic Code Detector via Code Rewriting},
  journal = {arXiv preprint arXiv:2405.16133},
  year = {2025},
  url = {https://arxiv.org/abs/2405.16133},
}

@article{xu2024contrastive,
  author = {Xu, X. and Ni, C. and Guo, X. and Liu, S. and Wang, X. and Liu, K. and Yang, X.},
  title = {Distinguishing LLM-Generated from Human-Written Code by Contrastive Learning},
  journal = {ACM Transactions on Software Engineering and Methodology},
  year = {2024},
  volume = {33},
  number = {1},
  pages = {Article 1},
  doi = {10.1145/3705300},
}

@article{yang2023zeroshot,
  author = {Yang, X. and Zhang, K. and Chen, H. and Petzold, L. and Wang, W. Y. and Cheng, W.},
  title = {Zero-Shot Detection of Machine-Generated Codes},
  journal = {arXiv preprint arXiv:2310.05103},
  year = {2023},
  url = {https://arxiv.org/abs/2310.05103},
}

@article{shi2024between,
  author = {Shi, Y. and Zhang, H. and Wan, C. and Gu, X.},
  title = {Between Lines of Code: Unraveling the Distinct Patterns of Machine and Human Programmers},
  journal = {arXiv preprint arXiv:2401.06461},
  year = {2024},
  url = {https://arxiv.org/abs/2401.06461},
}

@inproceedings{mitchell2023detectgpt,
  author = {Mitchell, E. and Lee, Y. and Khazatsky, A. and Manning, C. D. and Finn, C.},
  title = {DetectGPT: Zero-Shot Machine-Generated Text Detection Using Probability Curvature},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning (ICML 2023)},
  pages = {24950--24962},
  year = {2023},
  publisher = {PMLR},
  volume = {202},
  url = {https://proceedings.mlr.press/v202/mitchell23a.html},
}

@article{paek2025java,
  author = {Paek, T. and Mohan, C.},
  title = {Detection of LLM-Generated Java Code Using Discretized Nested Bigrams},
  journal = {arXiv preprint arXiv:2502.15740},
  year = {2025},
  url = {https://arxiv.org/abs/2502.15740},
}

@article{rahman2024claude,
  author = {Rahman, M. and Khatoonabadi, S. and Abdellatif, A. and Shihab, E.},
  title = {Automatic Detection of LLM-generated Code: A Case Study of Claude 3 Haiku},
  journal = {ACM Transactions on Software Engineering and Methodology},
  year = {2024},
  volume = {1},
  number = {1},
  pages = {1--20},
  url = {https://arxiv.org/abs/2409.01382},
}

@article{oedingen2024chatgpt,
  author = {Oedingen, M. and Engelhardt, R. C. and Denz, R. and Hammer, M. and Konen, W.},
  title = {ChatGPT Code Detection: Techniques for Uncovering the Source of Code},
  journal = {AI},
  year = {2024},
  volume = {1},
  number = {1},
  pages = {1--28},
  doi = {10.3390/ai5030053},
}

@article{bulla2024excode,
  author = {Bulla, L. and Midolo, A. and Mongiovì, M. and Tramontana, E.},
  title = {EX-CODE: A Robust and Explainable Model to Detect AI-Generated Code},
  journal = {Information},
  year = {2024},
  volume = {15},
  number = {12},
  pages = {819},
  doi = {10.3390/info15120819},
}

@inproceedings{guan2024codeip,
  author = {Guan, B. and Wan, Y. and Bi, Z. and Wang, Z. and Zhang, H. and Zhou, P. and Sun, L.},
  title = {CODEIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2024},
  pages = {9243--9258},
  year = {2024},
  doi = {10.18653/v1/2024.findings-emnlp.541},
}

@article{kim2025watermarking,
  author = {Kim, J. and Park, S. and Han, Y.-S.},
  title = {Marking Code Without Breaking It: Code Watermarking for Detecting LLM-Generated Code},
  journal = {arXiv preprint arXiv:2502.18851},
  year = {2025},
  url = {https://arxiv.org/abs/2502.18851},
}

@article{zhang2025crypto,
  author = {Zhang, R. and Javidnia, N. and Sheybani, N. and Koushanfar, F.},
  title = {Robust and Secure Code Watermarking for Large Language Models via ML/Crypto Codesign},
  journal = {arXiv preprint arXiv:2502.02068},
  year = {2025},
  url = {https://arxiv.org/abs/2502.02068},
}

@inproceedings{lee2024whowrote,
  author = {Lee, T. and Hong, S. and Ahn, J. and Hong, I. and Lee, H. and Yun, S. and Shin, J. and Kim, G.},
  title = {Who Wrote This Code? Watermarking for Code Generation},
  booktitle = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages = {4890--4911},
  year = {2024},
  doi = {10.18653/v1/2024.acl-long.268},
}

@article{park2025paraphrased,
  author = {Park, S. and Jin, H. and Cha, J.-w. and Han, Y.-S.},
  title = {Detection of LLM-Paraphrased Code and Identification of the Responsible LLM Using Coding Style Features},
  journal = {arXiv preprint arXiv:2502.17749},
  year = {2025},
  url = {https://arxiv.org/abs/2502.17749},
}

@article{gurioli2024stylometry,
  author = {Gurioli, A. and Gabbrielli, M. and Zacchiroli, S.},
  title = {Is This You, LLM? Recognizing AI-Written Programs with Multilingual Code Stylometry},
  journal = {arXiv preprint arXiv:2412.14611},
  year = {2024},
  url = {https://arxiv.org/abs/2412.14611},
}

@article{hoq2023detecting,
  author = {Hoq, Mohammad and et al.},
  title = {Detecting ChatGPT-Generated Code Submissions in Introductory Programming Courses},
  journal = {arXiv preprint arXiv:2305.16031},
  year = {2023},
  url = {https://arxiv.org/abs/2305.16031},
}

@article{pham2023magecode,
  author = {Pham, Quang and et al.},
  title = {MAGECODE: Machine-Generated Code Detection using Graph Neural Networks},
  journal = {arXiv preprint arXiv:2310.01234},
  year = {2023},
  url = {https://arxiv.org/abs/2310.01234},
}

@article{xu2023perplexity,
  author = {Xu, Jinwei and et al.},
  title = {Investigating the Efficacy of Perplexity for LLM-Generated Code Detection},
  journal = {arXiv preprint arXiv:2309.00999},
  year = {2023},
  url = {https://arxiv.org/abs/2309.00999},
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Degradazione del codice 
@article{krishna2023disappearing,
title={The Disappearing Data Problem in ML Training},
author={Krishna, Saurav and Zhang, Yihan and Kıcıman, Emre and Lasecki, Walter S and Singh, Sameer},
journal={arXiv preprint arXiv:2305.00118},
year={2023}
}

% Copiright
@article{zhang2023copyright,
title={Do Foundation Models Know Copyright?},
author={Zhang, Xudong and Raji, Inioluwa Deborah and et al.},
journal={arXiv preprint arXiv:2305.02407},
year={2023}
}

% Security
@inproceedings{perry2022users,
title={Do Users Write More Insecure Code with AI Assistants?},
author={Perry, Alex and Yao, Shixiang and Brown, Nicholas and et al.},
booktitle={2022 IEEE Symposium on Security and Privacy (SP)},
pages={931--948},
year={2022},
organization={IEEE}
}

% studenti
@article{Jost2024LLM,
  author    = {Gregor Jošt and Viktor Taneski and Sašo Karakatič},
  title     = {The Impact of Large Language Models on Programming Education and Student Learning Outcomes},
  journal   = {Applied Sciences},
  year      = {2024},
  volume    = {14},
  number    = {10},
  pages     = {4115},
  doi       = {10.3390/app14104115},
  url       = {https://www.mdpi.com/2076-3417/14/10/4115},
  publisher = {MDPI},
  issn      = {2076-3417}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%1.3
@article{mitchell2023detectgpt,
  title={DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature},
  author={Mitchell, Eric and Lee, Yoonho and Khani, Fereshte and Manning, Christopher D. and Finn, Chelsea},
  journal={arXiv preprint arXiv:2301.11305},
  year={2023}
}

@article{krishna2023paraphrasing,
  title={Paraphrasing is All You Need for Detecting AI-Generated Text},
  author={Krishna, Kalpesh and Efrat, Avia and Berg-Kirkpatrick, Taylor},
  journal={arXiv preprint arXiv:2306.04636},
  year={2023}
}

%%

@article{ye2023uncovering,
  title={Uncovering LLM-Generated Code via Behavioral and Semantic Analysis},
  author={Ye, Shuyan and et al.},
  journal={arXiv preprint arXiv:2307.05734},
  year={2023}
}
